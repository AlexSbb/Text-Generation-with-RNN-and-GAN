{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN-Autoencoder.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1iu_mpuS9YwiUe9O8kdRIFprZigbdYjNj",
      "authorship_tag": "ABX9TyM623LeX6OiXiXdUIuBMHKe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlexSbb/Text-Generation-with-RNN-and-GAN/blob/main/CS13ColabNotebooks/RNN_Autoencoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vtx-egydOGoG"
      },
      "source": [
        "Import all necessary libraries:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KoK2MxRDLkou",
        "outputId": "f5fbd3a0-5056-467b-d41d-ceff4fe5488b"
      },
      "source": [
        "import numpy as np\r\n",
        "import tensorflow as tf\r\n",
        "import tensorflow_probability as tfp\r\n",
        "import time\r\n",
        "import math\r\n",
        "import random\r\n",
        "print('TensorFlow version (should be 2.4.1):  ',tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow version (should be 2.4.1):   2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPppKMxkOuIw"
      },
      "source": [
        "# Open, read and process the text file\r\n",
        "In our case the we use the log file from an Elevator Group Control System simulation - \"ElevatorLogFile.txt\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHi_SsjgOkGR",
        "outputId": "baf8d92d-c89c-4d04-d358-ee67a26a85bc"
      },
      "source": [
        "PATH_TO_FILE = \"/content/drive/MyDrive/Colab Notebooks/CS13ColabNotebooks/ElevatorLogFile.txt\"\r\n",
        "\r\n",
        "# Open and read the whole txt file\r\n",
        "def open_and_read_test_file (path :str):\r\n",
        "    with open(path) as text_file:\r\n",
        "        text = text_file.read()\r\n",
        "    print('Number of characters in the log file:', len(text))\r\n",
        "    print('Number of words in the log file (with whitespace as a splitter):', len(text.split()))\r\n",
        "    return text\r\n",
        "\r\n",
        "file_text = open_and_read_test_file(PATH_TO_FILE)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of characters in the log file: 73037\n",
            "Number of words in the log file (with whitespace as a splitter): 9010\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDu1Fqi2Y5d5"
      },
      "source": [
        "Creating a dictionary from a text file. \r\n",
        "We will use a character-level dictionary. To do this, you need to count the number of unique characters in the text file. Each character is then assigned a unique sequence number. As a result, we will get two dictionaries, one for converting characters to numbers, and the second for reverse conversion."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAASttqCZk-F",
        "outputId": "f75452e1-0f35-4b97-a7b0-ba68d585eafb"
      },
      "source": [
        "def dictionary_from_text(text:str):\r\n",
        "  set_of_uniq_ch = set(text) # set of uniq characters from text\r\n",
        "  print('Number of uniq characters in the log file:', len(set_of_uniq_ch))\r\n",
        "  char_to_index = {char:index for index, char in enumerate(set_of_uniq_ch)}\r\n",
        "  index_to_char = {index:char for char,index in char_to_index.items()}\r\n",
        "  return char_to_index, index_to_char\r\n",
        "\r\n",
        "char_to_index, index_to_char =  dictionary_from_text(file_text)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of uniq characters in the log file: 54\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_qiB1ynb6cw"
      },
      "source": [
        "In order to make it convenient to use dictionaries, I will create two auxiliary functions, for converting text to numbers and for reverse conversion."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Efsc1wT_awSH"
      },
      "source": [
        "def text_to_numbers(dictionary: dict, text: str):\r\n",
        "  numbers = [dictionary[char] for char in text]\r\n",
        "  return numbers\r\n",
        "\r\n",
        "def numbers_to_text(dictionary: dict, numbers: list):\r\n",
        "  text =\"\"\r\n",
        "  for num in numbers:\r\n",
        "    # text += str(dictionary[num])\r\n",
        "    text += dictionary[num]\r\n",
        "  return text"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGiZZKUMcg3o"
      },
      "source": [
        "Now we can easily convert our entire text file to numbers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfbEQXw9crGj",
        "outputId": "38959a2c-04a8-4361-e407-8cfd6253a7cc"
      },
      "source": [
        "whole_text_as_numbers = text_to_numbers(char_to_index, file_text)\r\n",
        "\r\n",
        "# Test:\r\n",
        "first_64_numbers = whole_text_as_numbers[0:64]\r\n",
        "print(\"First 64 numberst from 'whole_text_as_numbers':\")\r\n",
        "print(first_64_numbers)\r\n",
        "# test reverse conversion\r\n",
        "reverse_conversion = numbers_to_text(index_to_char, first_64_numbers)\r\n",
        "print(\"Conversin from numbers to text:\")\r\n",
        "print(reverse_conversion)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First 64 numberst from 'whole_text_as_numbers':\n",
            "[42, 0, 30, 25, 37, 1, 40, 36, 37, 15, 15, 17, 36, 33, 42, 0, 30, 25, 37, 1, 40, 36, 37, 15, 15, 17, 36, 30, 36, 17, 16, 41, 49, 38, 38, 38, 29, 14, 0, 30, 43, 16, 35, 35, 17, 1, 6, 17, 36, 33, 42, 0, 30, 44, 17, 1, 17, 36, 16, 40, 26, 1, 6, 30]\n",
            "Conversin from numbers to text:\n",
            "0: Controller_0: Controller ready...\n",
            "1: Passenger_0: Generating \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9d03vFk54Yg",
        "outputId": "d0108662-2801-46d0-901d-432e373b790e"
      },
      "source": [
        "#Split the input sequence into x and y, where x and y have the same shape\r\n",
        "def split_to_x_y(sequence: list, x_length: int = 128, step: int = 3):\r\n",
        "    x = []\r\n",
        "    y = []\r\n",
        "    for i in range(0, len(sequence) - x_length, step):\r\n",
        "        x.append(np.array(sequence[i: i + x_length]) )\r\n",
        "        y.append(np.array(sequence[i+1:i+1 + x_length]))\r\n",
        "    print(\"Number of sequences:\", len(x))\r\n",
        "    x = np.array(x)\r\n",
        "    y = np.array(y)   \r\n",
        "    print('x.shape=', x.shape)\r\n",
        "    print('y.shape=', y.shape)\r\n",
        "    return x , y\r\n",
        "\r\n",
        "# Left one last element in a sequence\r\n",
        "def take_last_element(original_y: np.array):\r\n",
        "  y_1 = [y[-1] for y in original_y]\r\n",
        "  y_1 = np.array(y_1) \r\n",
        "  print('y_1.shape=', y_1.shape)\r\n",
        "  return y_1\r\n",
        "\r\n",
        "sequence_length = 32\r\n",
        "x, y = split_to_x_y(whole_text_as_numbers, x_length = sequence_length, step = 3)\r\n",
        "# y_1 = take_last_element(y)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of sequences: 24335\n",
            "x.shape= (24335, 32)\n",
            "y.shape= (24335, 32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XV5jhz6QNHJ"
      },
      "source": [
        "# One-hot encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zli4_KvWQSGy",
        "outputId": "8c517d83-a9ec-439c-e293-b9428a7afc88"
      },
      "source": [
        "dictionary_lenth = len(index_to_char)\r\n",
        "one_hot_matrix = np.eye(dictionary_lenth)\r\n",
        "print('one_hot_matrix.shape=', one_hot_matrix.shape)\r\n",
        "\r\n",
        "def array_of_seq_to_one_hot(array_of_seq:np.array, matrix: np.array):\r\n",
        "  one_hot_seq = np.array(\r\n",
        "    [np.array([matrix[:,ind] for ind in seq]) for seq in array_of_seq]\r\n",
        "    )\r\n",
        "  return one_hot_seq\r\n",
        "\r\n",
        "def array_of_int_to_one_hot(array_of_int:np.array, matrix: np.array):\r\n",
        "  one_hot_seq = np.array(\r\n",
        "    np.array([matrix[:,ind] for ind in array_of_int])\r\n",
        "    )\r\n",
        "  return one_hot_seq\r\n",
        "\r\n",
        "one_hot_x = array_of_seq_to_one_hot(x,one_hot_matrix)\r\n",
        "one_hot_y = array_of_seq_to_one_hot(y,one_hot_matrix)\r\n",
        "\r\n",
        "# one_hot_y_1 = array_of_int_to_one_hot(y_1,one_hot_matrix)\r\n",
        "\r\n",
        "print('one_hot_x.shape:', one_hot_x.shape, \"# (batch_size, sequence_length, vocab_size)\")\r\n",
        "print('one_hot_y.shape:', one_hot_y.shape)\r\n",
        "# print('one_hot_y_1.shape:', one_hot_y_1.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "one_hot_matrix.shape= (54, 54)\n",
            "one_hot_x.shape: (24335, 32, 54) # (batch_size, sequence_length, vocab_size)\n",
            "one_hot_y.shape: (24335, 32, 54)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCDYBW5FM4jz"
      },
      "source": [
        "# RNN-Autoencoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAx9O8gENRnR"
      },
      "source": [
        "## Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOc1ro57NQap"
      },
      "source": [
        "class Encoder(tf.keras.Model):\r\n",
        "  def __init__(self,):\r\n",
        "    super(Encoder, self).__init__()\r\n",
        "\r\n",
        "    self.RNN_1 = tf.keras.layers.GRU(128, return_sequences=True)\r\n",
        "    self.RNN_2 = tf.keras.layers.GRU(64, return_sequences=True)\r\n",
        "    self.RNN_3 = tf.keras.layers.GRU(16, return_state=True)\r\n",
        "\r\n",
        "  def call(self, x):\r\n",
        "    x = self.RNN_1(x)\r\n",
        "    x = self.RNN_2(x)\r\n",
        "    whole_seq_output, final_state = self.RNN_3(x)\r\n",
        "    z = tf.concat([whole_seq_output, final_state],1) # Output and state fron last time step\r\n",
        "    return z, final_state"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFEWTQKMfJhZ"
      },
      "source": [
        "### Test Encoder shapes (dimentions)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmqiwImAOkGo"
      },
      "source": [
        "text_encoder = Encoder()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0h-QBQDhO4rv",
        "outputId": "fafbbb4a-792b-41be-ead5-4c90d42d26e3"
      },
      "source": [
        "test_encoder_input = one_hot_x[1:2]\r\n",
        "print('test_encoder_input spahe:',test_encoder_input.shape)\r\n",
        "test_encoder_output_z, test_encoder_output_final_state = text_encoder(test_encoder_input)\r\n",
        "print('test_encoder_output_z shape:', test_encoder_output_z.shape)\r\n",
        "print('test_encoder_output_final_state shape:', test_encoder_output_final_state.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_encoder_input spahe: (1, 32, 54)\n",
            "test_encoder_output_z shape: (1, 32)\n",
            "test_encoder_output_final_state shape: (1, 16)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePm3iKg9QvTP",
        "outputId": "80fd2d4b-43ba-47f6-e6b2-2d7c69062d15"
      },
      "source": [
        "decoder_input = tf.reshape(test_encoder_output_z ,[test_encoder_output_z .shape[0],1,test_encoder_output_z.shape[1]])\r\n",
        "print('decoder_input shape v1:', decoder_input.shape)\r\n",
        "\r\n",
        "decoder_input = tf.repeat(decoder_input,[sequence_length],axis=1)\r\n",
        "decoder_input.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "decoder_input shape v1: (1, 1, 32)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([1, 32, 32])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "889m9Y84R6cv"
      },
      "source": [
        "## Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4V94Ijp-R51n"
      },
      "source": [
        "class Decoder(tf.keras.Model):\r\n",
        "  def __init__(self,dictionary_lenth=54):\r\n",
        "    super(Decoder, self).__init__()\r\n",
        "\r\n",
        "    self.RNN_1 = tf.keras.layers.GRU(16, return_sequences=True)\r\n",
        "    self.RNN_2 = tf.keras.layers.GRU(64, return_sequences=True)\r\n",
        "    self.RNN_3 = tf.keras.layers.GRU(128, return_sequences=True)\r\n",
        "    self.Dense = tf.keras.layers.Dense(dictionary_lenth, activation=\"softmax\") \r\n",
        "\r\n",
        "  def call(self, x, inital_state = None):\r\n",
        "    decoder_input = tf.reshape(x ,[tf.shape(x)[0], 1, tf.shape(x)[1] ])\r\n",
        "    decoder_input = tf.repeat(decoder_input, x.shape[1]  ,axis=1)\r\n",
        "    x = self.RNN_1(decoder_input, inital_state)\r\n",
        "    x = self.RNN_2(x)\r\n",
        "    x = self.RNN_3(x)\r\n",
        "    z= self.Dense(x)\r\n",
        "    return z"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6u8ZFQ7EfAuz"
      },
      "source": [
        "### Test Decoder shapes (dimentions)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6L9zB3jTYIh",
        "outputId": "c6c74028-031c-4878-ea32-25a912ef0f60"
      },
      "source": [
        "test_decoder = Decoder(dictionary_lenth=dictionary_lenth)\r\n",
        "test_decoder_output = test_decoder(test_encoder_output_z)\r\n",
        "test_decoder_output.shape"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([1, 32, 54])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYVhddmQPWhZ"
      },
      "source": [
        "# Autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nCungDwT9Bj"
      },
      "source": [
        "class Autoencoder(tf.keras.Model):\r\n",
        "  def __init__(self,):\r\n",
        "    super(Autoencoder, self).__init__() \r\n",
        "    self.encoder = Encoder()\r\n",
        "    self.decoder = Decoder()\r\n",
        "\r\n",
        "  def call(self, x):\r\n",
        "    encoded,state = self.encoder(x)\r\n",
        "    decoded = self.decoder(encoded,state)\r\n",
        "    return decoded\r\n",
        "\r\n",
        "# tf.keras.layers.Dropout(0.2),"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNV_kKj-ULN1"
      },
      "source": [
        "autoencoder = Autoencoder()\r\n",
        "\r\n"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2hQ82qdeAUb"
      },
      "source": [
        "### Test Autoencoder shapes (dimentions)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEB-I1IhVPeS",
        "outputId": "2d9c3227-59ed-492c-af86-e49a715ffcb6"
      },
      "source": [
        "z,s = autoencoder.encoder(one_hot_x[0:16])\r\n",
        "print('z shape:', z.shape)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "z shape: (16, 32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEc_Q-CvXEvY",
        "outputId": "e4843a85-bb66-49e4-f61c-f77759c282cb"
      },
      "source": [
        "autoencoder_output = autoencoder.decoder(z,s)\r\n",
        "autoencoder_output.shape"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([16, 32, 54])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUC13KxReHm_"
      },
      "source": [
        "### Fit Autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YclySwM1Mj6u",
        "outputId": "13e8a2d9-638f-46b7-87f5-209503969d16"
      },
      "source": [
        "autoencoder.compile(optimizer='adam', loss=tf.losses.categorical_crossentropy)\r\n",
        "autoencoder.fit(x = one_hot_x,y = one_hot_x, epochs=15)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "761/761 [==============================] - 16s 13ms/step - loss: 0.9139\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fbbc4285ed0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-qDkuOceXaO"
      },
      "source": [
        "### Test Autoencoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQWK3CGfOkHU"
      },
      "source": [
        "#### Encode a text to a laten vector and cell state"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxFE0laJO8Dh",
        "outputId": "cac260f1-efea-491d-dda3-1f78d523e4f3"
      },
      "source": [
        "sample_text = file_text[0:32]\r\n",
        "converted_sample_text = text_to_numbers(char_to_index, sample_text)\r\n",
        "one_hot_sample_text = np.array([array_of_int_to_one_hot(converted_sample_text, one_hot_matrix)])\r\n",
        "encoder_input = one_hot_sample_text\r\n",
        "print(\"encoder_input shape\", encoder_input.shape)\r\n",
        "\r\n",
        "encoder_output,state = autoencoder.encoder(one_hot_sample_text)\r\n",
        "print(\"encoder output shape\", encoder_output.shape)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "encoder_input shape (1, 32, 54)\n",
            "encoder output shape (1, 32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQevgGYpQ0QJ"
      },
      "source": [
        "#### Decode text from the the laten vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdl4LtKVQ_Dj",
        "outputId": "102c3df5-00fa-4b08-c5c5-7aff36280d0f"
      },
      "source": [
        "decoder_output = autoencoder.decoder(encoder_output,state)\r\n",
        "print('Decoder output shape', decoder_output.shape)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decoder output shape (1, 32, 54)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmvRqDDselRO"
      },
      "source": [
        "#### Convert softmax output to numbers and numbers to text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctOwtsNaRYAu",
        "outputId": "47410560-d285-4dca-bb88-22c8fb1e2068"
      },
      "source": [
        "pred_array = tf.squeeze(decoder_output).numpy()\r\n",
        "temp_texp = '' \r\n",
        "for vec in pred_array:\r\n",
        "  ind = np.array(np.argmax(vec), ndmin=1 )\r\n",
        "  char = numbers_to_text(index_to_char, ind)\r\n",
        "  # print(char)\r\n",
        "  temp_texp +=char\r\n",
        "\r\n",
        "print('Original text:', sample_text)\r\n",
        "print('Decoded text:', temp_texp)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original text: 0: Controller_0: Controller read\n",
            "Decoded text: :: Controller_0: Clreeol errrraa\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}