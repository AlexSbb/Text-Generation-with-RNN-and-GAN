{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN-Autoencoder.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1jdAUT9MZyuLGKy15CHUSdV8GwdVhqvSL",
      "authorship_tag": "ABX9TyNDqaoZkYK7sJ7KTFSeYa+m",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlexSbb/Text-Generation-with-RNN-and-GAN/blob/main/CS13ColabNotebooks/RNN_Autoencoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vtx-egydOGoG"
      },
      "source": [
        "Import all necessary libraries:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KoK2MxRDLkou",
        "outputId": "353c5675-88bd-4f00-d2a8-3ac227f5043c"
      },
      "source": [
        "import numpy as np\r\n",
        "import tensorflow as tf\r\n",
        "import tensorflow_probability as tfp\r\n",
        "import time\r\n",
        "import math\r\n",
        "import random\r\n",
        "print('TensorFlow version (should be 2.4.1):  ',tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow version (should be 2.4.1):   2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPppKMxkOuIw"
      },
      "source": [
        "# Open, read and process the text file\r\n",
        "In our case the we use the log file from an Elevator Group Control System simulation - \"ElevatorLogFile.txt\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHi_SsjgOkGR",
        "outputId": "1266b988-74a4-4602-d611-5f56f77bf029"
      },
      "source": [
        "PATH_TO_FILE = \"/content/drive/MyDrive/Colab Notebooks/CS13ColabNotebooks/ElevatorLogFile.txt\"\r\n",
        "\r\n",
        "# Open and read the whole txt file\r\n",
        "def open_and_read_test_file (path :str):\r\n",
        "    with open(path) as text_file:\r\n",
        "        text = text_file.read()\r\n",
        "    print('Number of characters in the log file:', len(text))\r\n",
        "    print('Number of words in the log file (with whitespace as a splitter):', len(text.split()))\r\n",
        "    return text\r\n",
        "\r\n",
        "file_text = open_and_read_test_file(PATH_TO_FILE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of characters in the log file: 73037\n",
            "Number of words in the log file (with whitespace as a splitter): 9010\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDu1Fqi2Y5d5"
      },
      "source": [
        "Creating a dictionary from a text file. \r\n",
        "We will use a character-level dictionary. To do this, you need to count the number of unique characters in the text file. Each character is then assigned a unique sequence number. As a result, we will get two dictionaries, one for converting characters to numbers, and the second for reverse conversion."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAASttqCZk-F",
        "outputId": "5a564bdd-ed92-40ec-f6e6-338d15a1bf0f"
      },
      "source": [
        "def dictionary_from_text(text:str):\r\n",
        "  set_of_uniq_ch = set(text) # set of uniq characters from text\r\n",
        "  print('Number of uniq characters in the log file:', len(set_of_uniq_ch))\r\n",
        "  char_to_index = {char:index for index, char in enumerate(set_of_uniq_ch)}\r\n",
        "  index_to_char = {index:char for char,index in char_to_index.items()}\r\n",
        "  return char_to_index, index_to_char\r\n",
        "\r\n",
        "char_to_index, index_to_char =  dictionary_from_text(file_text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of uniq characters in the log file: 54\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_qiB1ynb6cw"
      },
      "source": [
        "In order to make it convenient to use dictionaries, I will create two auxiliary functions, for converting text to numbers and for reverse conversion."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Efsc1wT_awSH"
      },
      "source": [
        "def text_to_numbers(dictionary: dict, text: str):\r\n",
        "  numbers = [dictionary[char] for char in text]\r\n",
        "  return numbers\r\n",
        "\r\n",
        "def numbers_to_text(dictionary: dict, numbers: list):\r\n",
        "  text =\"\"\r\n",
        "  for num in numbers:\r\n",
        "    # text += str(dictionary[num])\r\n",
        "    text += dictionary[num]\r\n",
        "  return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGiZZKUMcg3o"
      },
      "source": [
        "Now we can easily convert our entire text file to numbers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfbEQXw9crGj",
        "outputId": "9fe57dc4-beac-492f-aa1d-4177ee3f368b"
      },
      "source": [
        "whole_text_as_numbers = text_to_numbers(char_to_index, file_text)\r\n",
        "\r\n",
        "# Test:\r\n",
        "first_64_numbers = whole_text_as_numbers[0:64]\r\n",
        "print(\"First 64 numberst from 'whole_text_as_numbers':\")\r\n",
        "print(first_64_numbers)\r\n",
        "# test reverse conversion\r\n",
        "reverse_conversion = numbers_to_text(index_to_char, first_64_numbers)\r\n",
        "print(\"Conversin from numbers to text:\")\r\n",
        "print(reverse_conversion)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First 64 numberst from 'whole_text_as_numbers':\n",
            "[19, 36, 45, 12, 46, 47, 24, 7, 46, 39, 39, 41, 7, 31, 19, 36, 45, 12, 46, 47, 24, 7, 46, 39, 39, 41, 7, 45, 7, 41, 20, 6, 42, 51, 51, 51, 52, 48, 36, 45, 0, 20, 2, 2, 41, 47, 37, 41, 7, 31, 19, 36, 45, 30, 41, 47, 41, 7, 20, 24, 27, 47, 37, 45]\n",
            "Conversin from numbers to text:\n",
            "0: Controller_0: Controller ready...\n",
            "1: Passenger_0: Generating \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9d03vFk54Yg",
        "outputId": "fdfb4acc-c3b4-4e66-f892-de7ea10f57d5"
      },
      "source": [
        "#Split the input sequence into x and y, where x and y have the same shape\r\n",
        "def split_to_x_y(sequence: list, x_length: int = 128, step: int = 3):\r\n",
        "    x = []\r\n",
        "    y = []\r\n",
        "    for i in range(0, len(sequence) - x_length, step):\r\n",
        "        x.append(np.array(sequence[i: i + x_length]) )\r\n",
        "        y.append(np.array(sequence[i+1:i+1 + x_length]))\r\n",
        "    print(\"Number of sequences:\", len(x))\r\n",
        "    x = np.array(x)\r\n",
        "    y = np.array(y)   \r\n",
        "    print('x.shape=', x.shape)\r\n",
        "    print('y.shape=', y.shape)\r\n",
        "    return x , y\r\n",
        "\r\n",
        "# Left one last element in a sequence\r\n",
        "def take_last_element(original_y: np.array):\r\n",
        "  y_1 = [y[-1] for y in original_y]\r\n",
        "  y_1 = np.array(y_1) \r\n",
        "  print('y_1.shape=', y_1.shape)\r\n",
        "  return y_1\r\n",
        "\r\n",
        "x, y = split_to_x_y(whole_text_as_numbers, x_length = 32, step = 3)\r\n",
        "# y_1 = take_last_element(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of sequences: 24335\n",
            "x.shape= (24335, 32)\n",
            "y.shape= (24335, 32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XV5jhz6QNHJ"
      },
      "source": [
        "# One-hot encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zli4_KvWQSGy",
        "outputId": "fbcaf8d8-ebe3-475d-b782-443c27b84a99"
      },
      "source": [
        "dictionary_lenth = len(index_to_char)\r\n",
        "one_hot_matrix = np.eye(dictionary_lenth)\r\n",
        "print('one_hot_matrix.shape=', one_hot_matrix.shape)\r\n",
        "\r\n",
        "def array_of_seq_to_one_hot(array_of_seq:np.array, matrix: np.array):\r\n",
        "  one_hot_seq = np.array(\r\n",
        "    [np.array([matrix[:,ind] for ind in seq]) for seq in array_of_seq]\r\n",
        "    )\r\n",
        "  return one_hot_seq\r\n",
        "\r\n",
        "def array_of_int_to_one_hot(array_of_int:np.array, matrix: np.array):\r\n",
        "  one_hot_seq = np.array(\r\n",
        "    np.array([matrix[:,ind] for ind in array_of_int])\r\n",
        "    )\r\n",
        "  return one_hot_seq\r\n",
        "\r\n",
        "one_hot_x = array_of_seq_to_one_hot(x,one_hot_matrix)\r\n",
        "one_hot_y = array_of_seq_to_one_hot(y,one_hot_matrix)\r\n",
        "\r\n",
        "# one_hot_y_1 = array_of_int_to_one_hot(y_1,one_hot_matrix)\r\n",
        "\r\n",
        "print('one_hot_x.shape:', one_hot_x.shape, \"# (batch_size, sequence_length, vocab_size)\")\r\n",
        "print('one_hot_y.shape:', one_hot_y.shape)\r\n",
        "# print('one_hot_y_1.shape:', one_hot_y_1.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "one_hot_matrix.shape= (54, 54)\n",
            "one_hot_x.shape: (24335, 32, 54) # (batch_size, sequence_length, vocab_size)\n",
            "one_hot_y.shape: (24335, 32, 54)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYVhddmQPWhZ"
      },
      "source": [
        "# Autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_OT86bwL3Uz"
      },
      "source": [
        "class Autoencoder(tf.keras.Model):\r\n",
        "  def __init__(self,):\r\n",
        "    super(Autoencoder, self).__init__() \r\n",
        "    self.encoder = tf.keras.Sequential([                                       \r\n",
        "    tf.keras.layers.LSTM(64, return_sequences=True),\r\n",
        "    tf.keras.layers.Dropout(0.2),\r\n",
        "    tf.keras.layers.LSTM(16, return_sequences=True),\r\n",
        "    tf.keras.layers.Dropout(0.1),\r\n",
        "    tf.keras.layers.LSTM(4, return_sequences=True) \r\n",
        "    ])\r\n",
        "    self.decoder = tf.keras.Sequential([\r\n",
        "    tf.keras.layers.LSTM(4, return_sequences=True),\r\n",
        "    tf.keras.layers.LSTM(16, return_sequences=True),\r\n",
        "    tf.keras.layers.LSTM(64, return_sequences=True),\r\n",
        "    tf.keras.layers.Dense(dictionary_lenth, activation=\"softmax\") \r\n",
        "\r\n",
        "    ])\r\n",
        "\r\n",
        "  def call(self, x):\r\n",
        "    encoded = self.encoder(x)\r\n",
        "    decoded = self.decoder(encoded)\r\n",
        "    return decoded\r\n",
        "\r\n",
        "autoencoder = Autoencoder()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YclySwM1Mj6u",
        "outputId": "e9240662-c3b6-46ab-f2f7-ba9d82b1a7b2"
      },
      "source": [
        "autoencoder.compile(optimizer='adam', loss=tf.losses.categorical_crossentropy)\r\n",
        "autoencoder.fit(x = one_hot_x,y = one_hot_x, epochs=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "761/761 [==============================] - 49s 13ms/step - loss: 3.4331\n",
            "Epoch 2/10\n",
            "761/761 [==============================] - 10s 13ms/step - loss: 2.0900\n",
            "Epoch 3/10\n",
            "761/761 [==============================] - 10s 13ms/step - loss: 0.7145\n",
            "Epoch 4/10\n",
            "761/761 [==============================] - 10s 13ms/step - loss: 0.4011\n",
            "Epoch 5/10\n",
            "761/761 [==============================] - 10s 14ms/step - loss: 0.2846\n",
            "Epoch 6/10\n",
            "761/761 [==============================] - 11s 14ms/step - loss: 0.2170\n",
            "Epoch 7/10\n",
            "761/761 [==============================] - 10s 14ms/step - loss: 0.1748\n",
            "Epoch 8/10\n",
            "761/761 [==============================] - 10s 13ms/step - loss: 0.1459\n",
            "Epoch 9/10\n",
            "761/761 [==============================] - 11s 14ms/step - loss: 0.1168\n",
            "Epoch 10/10\n",
            "761/761 [==============================] - 10s 13ms/step - loss: 0.0980\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3ac01a4d90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQWK3CGfOkHU"
      },
      "source": [
        "Encode a text to a laten vector 'z'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxFE0laJO8Dh",
        "outputId": "030b93ed-af8b-4975-d9f5-42a81b647a74"
      },
      "source": [
        "sample_text = file_text[0:32]\r\n",
        "converted_sample_text = text_to_numbers(char_to_index, sample_text)\r\n",
        "one_hot_sample_text = np.array([array_of_int_to_one_hot(converted_sample_text, one_hot_matrix)])\r\n",
        "encoder_input = one_hot_sample_text\r\n",
        "print(\"encoder_input shape\", encoder_input.shape)\r\n",
        "\r\n",
        "encoder_output = autoencoder.encoder(one_hot_sample_text)\r\n",
        "print(\"encoder output shape\", encoder_output.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "encoder_input shape (1, 32, 54)\n",
            "encoder output shape (1, 32, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQevgGYpQ0QJ"
      },
      "source": [
        "Decode text from the a laten vector 'Z'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdl4LtKVQ_Dj",
        "outputId": "cbe60cb6-4501-476a-af7b-ec0f5b1e1911"
      },
      "source": [
        "decoder_output = autoencoder.decoder(encoder_output)\r\n",
        "print('Decoder output shape', decoder_output.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decoder output shape (1, 32, 54)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctOwtsNaRYAu",
        "outputId": "970fdfb6-90db-4916-8571-6b5d4f4bdc6e"
      },
      "source": [
        "pred_array = tf.squeeze(decoder_output).numpy()\r\n",
        "temp_texp = '' \r\n",
        "for vec in pred_array:\r\n",
        "  ind = np.array(np.argmax(vec), ndmin=1 )\r\n",
        "  char = numbers_to_text(index_to_char, ind)\r\n",
        "  # print(char)\r\n",
        "  temp_texp +=char\r\n",
        "print(temp_texp)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0: Controller_0: Controller read\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}